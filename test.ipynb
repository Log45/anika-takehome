{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import markitdown\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict, Union, Any\n",
    "import os\n",
    "from utils import search_arxiv_simple, arxiv_to_faiss, search_arxiv_advanced, client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture Notes: Optimization for Machine Learning\n",
      "Machine Learning for Clinical Predictive Analytics\n",
      "Towards Modular Machine Learning Solution Development: Benefits and Trade-offs\n",
      "An Optimal Control View of Adversarial Machine Learning\n",
      "The Tribes of Machine Learning and the Realm of Computer Architecture\n",
      "A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning\n",
      "MLBench: How Good Are Machine Learning Clouds for Binary Classification Tasks on Structured Data?\n",
      "Data Pricing in Machine Learning Pipelines\n",
      "Understanding Bias in Machine Learning\n",
      "Introduction to Machine Learning: Class Notes 67577\n"
     ]
    }
   ],
   "source": [
    "search = search_arxiv_simple(\"machine learning\")\n",
    "results = client.results(search)\n",
    "res = list(results)\n",
    "for r in res:\n",
    "    print(r.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-electron quantum walks can probe entanglement and decoherence in an electron microscope\n",
      "Electron-electron scattering processes in quantum wells in a quantizing magnetic field\n",
      "Quantum-coherent light-electron interaction in an SEM\n",
      "Quantum description and properties of electrons emitted from pulsed nanotip electron sources\n",
      "Spin polarization of electrons in quantum wires\n",
      "Electron quantum optics as quantum signal processing\n",
      "Quantum optics of single electrons in quantum liquid and solid helium-4\n",
      "Electron--Electron Scattering in Quantum Wires and it's Possible Suppression due to Spin Effects\n",
      "Disordered electron liquid in double quantum well heterostructures: Renormalization group analysis and dephasing rate\n",
      "Insights into the Electron-Electron Interaction from Quantum Monte Carlo Calculations\n"
     ]
    }
   ],
   "source": [
    "search = search_arxiv_advanced(['all:electron', 'all:quantum'], ['all:dots', 'all:nuclear'])\n",
    "results = client.results(search)\n",
    "res = list(results)\n",
    "for r in res:\n",
    "    print(r.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: Extension of Transformational Machine Learning: Classification Problems\n",
      "Successfully downloaded: Transformative Machine Learning\n",
      "Successfully downloaded: Finding trainable sparse networks through Neural Tangent Transfer\n",
      "Successfully downloaded: Deep Learning and Symbolic Regression for Discovering Parametric Equations\n",
      "Successfully downloaded: An ensemble Multi-Agent System for non-linear classification\n",
      "Successfully downloaded: Automated Feedback Generation for a Chemistry Database and Abstracting Exercise\n",
      "Successfully downloaded: Carbon Emissions of Quantum Circuit Simulation: More than You Would Think\n",
      "Successfully downloaded: Self-Supervision for Tackling Unsupervised Anomaly Detection: Pitfalls and Opportunities\n",
      "Successfully downloaded: Online Performance Estimation with Unlabeled Data: A Bayesian Application of the Hui-Walter Paradigm\n",
      "Successfully downloaded: An experimental study on fairness-aware machine learning for credit scoring problem\n",
      "Successfully downloaded 10 out of 10 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Logan\\Documents\\CODE\\anika-takehome\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H2' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 17 documents from directory\n",
      "Split into 2306 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Logan\\Documents\\CODE\\anika-takehome\\utils.py:192: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "db = arxiv_to_faiss(search = search_arxiv_simple(\"transformer machine learning\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(\"language models\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n",
      "\n",
      "[21] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. JMLR, 2020.\n",
      "on the relative and absolute positions of tokens, allowing the model to capture sequential dependencies.\n",
      "[45] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a method for automatic evaluation of machine translation,” in Proceedings of the 40th annual meeting of the Association for Computational Linguis- tics, 2002, pp. 311–318.\n",
      "[27] J. Y. Tian, A. P. Kreuzer, P.-H. Chen, and H.-M. Will, “Waldorf: Wasteless language-model distillation on reading-comprehension,” arXiv preprint arXiv:1912.06638, 2019.\n",
      "\n",
      "[28] O. Zafrir, G. Boudoukh, P. Izsak, and M. Wasserblat, “Q8bert: Quantized\n",
      "\n",
      "8bit bert,” arXiv preprint arXiv:1910.06188, 2019.\n",
      "\n",
      "[29] X. Ma, P. Zhang, S. Zhang, N. Duan, Y. Hou, M. Zhou, and D. Song, “A tensorized transformer for language modeling,” in NeurIPS, 2019, pp. 2229–2239.\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
